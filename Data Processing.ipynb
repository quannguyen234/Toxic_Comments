{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#misc\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#nlp \n",
    "import re   \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer #Tokenizer for preprocessing\n",
    "preprop_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "# Tweet tokenizer does not split at apostophes which is what we want\n",
    "from nltk.tokenize import TweetTokenizer  \n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "tokenizer=TweetTokenizer()\n",
    "\n",
    "#settings\n",
    "start_time=time.time()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/0B1yuv8YaUVlZZ1RzMFJmc1ZsQmM/view\n",
    "appos = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(comment):\n",
    "    \"\"\"\n",
    "    This function receives comments and returns clean word-list\n",
    "    \"\"\"\n",
    "    #Convert to lower case , so that Hi and hi are the same\n",
    "    comment=comment.lower()\n",
    "    #remove \\n\n",
    "    comment=re.sub(\"\\\\n\",\" \",comment)\n",
    "    # remove leaky elements like ip,user\n",
    "    comment=re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\",comment)\n",
    "    #removing usernames\n",
    "    comment=re.sub(\"\\[\\[.*\\]\",\"\",comment)\n",
    "    \n",
    "    #Split the sentences into words\n",
    "    words=tokenizer.tokenize(comment)\n",
    "    \n",
    "    # aphostophe  replacement (ie)   you're --> you are  \n",
    "    words=[appos[word] if word in appos else word for word in words]\n",
    "    words=[lem.lemmatize(word, \"v\") for word in words]\n",
    "    # remove stopwords\n",
    "    words = [w for w in words if not w in eng_stopwords]\n",
    "    \n",
    "    clean_sent=\" \".join(words)\n",
    "    #remove any non alphanum,digit character\n",
    "    clean_sent=re.sub(\"\\W+\",\" \",clean_sent)\n",
    "    clean_sent=re.sub(\"  \",\" \",clean_sent)\n",
    "    \n",
    "    return(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment_text'] = data.iloc[:,0:2].comment_text.apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test set using Stratified sampling and Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_sizes(data_size, val_ratio, test_ratio):\n",
    "    val_size = int(data_size * val_ratio)\n",
    "    test_size = int(data_size * test_ratio)\n",
    "    train_size = data_size - val_size - test_size\n",
    "    return train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_sample(df, index_list, n_duplicates):\n",
    "    subset_df = df[df.index.isin(index_list)]\n",
    "    # list of lists\n",
    "    list_of_subsets = [subset_df]*n_duplicates\n",
    "    # subset_df = combine_subset(pd.DataFrame(), list_of_subsets)\n",
    "    combined_df = pd.concat(list_of_subsets, axis = 0, ignore_index = False)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combo_labels_dict(df):\n",
    "    labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "    # Create different group of toxics \n",
    "    labels_idx_dict = defaultdict(list)\n",
    "    labels_idx_dict[\"clean\"] = df[df[\"toxic_count\"] == 0].sample(frac=1,random_state=9).index\n",
    "    labels_idx_dict[\"combo_6_toxic\"] = df[df[\"toxic_count\"] == 6].sample(frac=1,random_state=9).index\n",
    "    labels_idx_dict[\"toxic\"] = df[(df[\"toxic_count\"] == 1) & (df[\"toxic\"] == 1)].sample(frac=1,random_state=9).index\n",
    "    labels_idx_dict[\"combo_2_obscene_and_insult\"] = df[(df[\"toxic_count\"] == 2) & (df[\"obscene\"] == 1) & (df[\"insult\"] == 1)].sample(frac=1,random_state=9).index\n",
    "    labels_idx_dict[\"combo_2_hate_and_insult\"] = df[(df[\"toxic_count\"] == 2) & (df[\"identity_hate\"] == 1) & (df[\"insult\"] == 1)].sample(frac=1,random_state=9).index\n",
    "    labels_idx_dict[\"combo_3_obscene_and_insult\"] = df[(df[\"toxic_count\"] == 3) & (df[\"obscene\"] == 1) & (df[\"insult\"] == 1)].sample(frac=1,random_state=9).index\n",
    "    labels_idx_dict[\"combo_4_wo_threat\"] = df[(df[\"toxic_count\"] == 4) & (df[\"threat\"] == 0)].sample(frac=1,random_state=9).index\n",
    "    for label_name in labels[1:]:\n",
    "        labels_idx_dict[f\"combo_2_toxic_and_{label_name}\"] = df[(df[\"toxic_count\"] == 2) & (df[label_name] == 1) & (df[\"toxic\"] == 1)].sample(frac=1,random_state=9).index\n",
    "    return labels_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_labels_combo_dict(labels_idx_dict):\n",
    "    for key_name, index_list in labels_idx_dict.items():\n",
    "        print(f\"{key_name.ljust(40,' ' )} {len(index_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stratified_train_val_test(df, val_ratio, test_ratio):\n",
    "    labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    OVERSAMPLING_TRAIN_MAX = 5000\n",
    "    OVERSAMPLING_VAL_MAX = 500\n",
    "    #create new column 'toxic_count'\n",
    "    df[\"toxic_count\"] = df.iloc[:,2:].sum(axis=1)\n",
    "\n",
    "    labels_idx_dict = get_combo_labels_dict(df)\n",
    "    print(f\"\\n{' ' * 10 } DATA DISTRIBUTION\")\n",
    "\n",
    "    over_sampling_group_list = [\"combo_6_toxic\", \"combo_2_obscene_and_insult\", \"combo_2_hate_and_insult\", \"combo_3_obscene_and_insult\", \"combo_2_toxic_and_severe_toxic\", \"combo_2_toxic_and_obscene\", \"combo_2_toxic_and_threat\", \"combo_2_toxic_and_insult\", \"combo_2_toxic_and_identity_hate\", \"combo_4_wo_threat\"]\n",
    "    train_indices, val_indices, test_indices, total_index_list = [], [], [], []\n",
    "    train_df_subset_list, val_df_subset_list, test_df_subset_list = [], [], []\n",
    "    for key_name, index_list in labels_idx_dict.items():\n",
    "        print(f\"{key_name.ljust(40,' ' )} {len(index_list)}\")\n",
    "        total_index_list.extend(index_list)\n",
    "        # Calculate size of dataset\n",
    "        data_size = len(index_list)\n",
    "        train_size, val_size, test_size = get_train_val_test_sizes(data_size, val_ratio, test_ratio)\n",
    "        \n",
    "        # Get indexes for each set\n",
    "        train_portion = index_list[:train_size]\n",
    "        val_portion = index_list[train_size:train_size+val_size]\n",
    "        test_portion = index_list[-test_size:]\n",
    "\n",
    "        # Append each portion \n",
    "        train_indices.extend(train_portion)\n",
    "        val_indices.extend(val_portion)\n",
    "        test_indices.extend(test_portion)\n",
    "\n",
    "        # Oversampling data\n",
    "        if key_name in over_sampling_group_list:\n",
    "            train_n_duplicates = OVERSAMPLING_TRAIN_MAX // len(train_portion) if len(train_portion) < OVERSAMPLING_TRAIN_MAX else 1\n",
    "            train_df_subset_list.append(create_sub_sample(df,train_portion,train_n_duplicates))\n",
    "            val_n_duplicates = OVERSAMPLING_VAL_MAX // len(val_portion) if len(val_portion) < OVERSAMPLING_VAL_MAX else 1\n",
    "            val_df_subset_list.append(create_sub_sample(df,val_portion,val_n_duplicates))\n",
    "\n",
    "    # Get the remaining group of data\n",
    "    other_toxic_indices = df[~df.index.isin(total_index_list)].sample(frac=1,random_state=9).index\n",
    "    key_name = \"remaing_toxic\"\n",
    "    print(f\"{key_name.ljust(40,' ' )} {len(other_toxic_indices)}\")\n",
    "\n",
    "    # Add the remaining data to the train test val indices list\n",
    "    data_size = len(other_toxic_indices)\n",
    "    train_size, val_size, test_size = get_train_val_test_sizes(data_size, val_ratio, test_ratio)\n",
    "     \n",
    "    # Get indexes for each set\n",
    "    train_portion = other_toxic_indices[:train_size]\n",
    "    val_portion = other_toxic_indices[train_size:train_size+val_size]\n",
    "    test_portion = other_toxic_indices[-test_size:]\n",
    "\n",
    "    # Append each portion \n",
    "    train_indices.extend(train_portion)\n",
    "    val_indices.extend(val_portion)\n",
    "    test_indices.extend(test_portion)\n",
    "\n",
    "    # Oversampling data\n",
    "    train_n_duplicates = OVERSAMPLING_TRAIN_MAX // len(train_portion) if len(train_portion) < OVERSAMPLING_TRAIN_MAX else 1\n",
    "    train_df_subset_list.append(create_sub_sample(df,train_portion,train_n_duplicates))\n",
    "    val_n_duplicates = OVERSAMPLING_VAL_MAX // len(val_portion) if len(val_portion) < OVERSAMPLING_VAL_MAX else 1\n",
    "    val_df_subset_list.append(create_sub_sample(df,val_portion,val_n_duplicates))\n",
    "\n",
    "    # Create the dataset from the indices \n",
    "    train_df = df[df.index.isin(train_indices)]\n",
    "    val_df = df[df.index.isin(val_indices)]\n",
    "    test_df = df[df.index.isin(test_indices)]\n",
    "\n",
    "    assert(len(df) == len(train_df)+len(val_df)+len(test_df))\n",
    "\n",
    "    # Add oversampling data\n",
    "    train_df_subset_list.append(train_df)\n",
    "    combined_train_df = pd.concat(train_df_subset_list, axis = 0, ignore_index = False)\n",
    "    val_df_subset_list.append(val_df)\n",
    "    combined_val_df = pd.concat(val_df_subset_list, axis = 0, ignore_index = False)\n",
    "\n",
    "    print(f\"\\n{' ' * 10 } TRAIN DATA DISTRIBUTION\")\n",
    "    labels_idx_dict = get_combo_labels_dict(combined_train_df)\n",
    "    print_labels_combo_dict(labels_idx_dict)\n",
    "\n",
    "    print(f\"\\n{' ' * 10 } DATASET\")\n",
    "\n",
    "    print(f\"TRAIN SIZE   {len(combined_train_df)}\")\n",
    "    print(f\"VAL SIZE     {len(combined_val_df)}\")\n",
    "    print(f\"TEST SIZE    {len(test_df)}\")\n",
    "\n",
    "    return combined_train_df.sample(frac=1,random_state=9), combined_val_df.sample(frac=1,random_state=9), test_df.sample(frac=1,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           DATA DISTRIBUTION\n",
      "clean                                    143346\n",
      "combo_6_toxic                            31\n",
      "toxic                                    5666\n",
      "combo_2_obscene_and_insult               181\n",
      "combo_2_hate_and_insult                  28\n",
      "combo_3_obscene_and_insult               3820\n",
      "combo_4_wo_threat                        1620\n",
      "combo_2_toxic_and_severe_toxic           41\n",
      "combo_2_toxic_and_obscene                1758\n",
      "combo_2_toxic_and_threat                 113\n",
      "combo_2_toxic_and_insult                 1215\n",
      "combo_2_toxic_and_identity_hate          136\n",
      "remaing_toxic                            1616\n",
      "\n",
      "           TRAIN DATA DISTRIBUTION\n",
      "clean                                    114678\n",
      "combo_6_toxic                            5025\n",
      "toxic                                    4534\n",
      "combo_2_obscene_and_insult               5075\n",
      "combo_2_hate_and_insult                  5016\n",
      "combo_3_obscene_and_insult               6112\n",
      "combo_4_wo_threat                        5184\n",
      "combo_2_toxic_and_severe_toxic           5016\n",
      "combo_2_toxic_and_obscene                5632\n",
      "combo_2_toxic_and_threat                 5005\n",
      "combo_2_toxic_and_insult                 5838\n",
      "combo_2_toxic_and_identity_hate          5060\n",
      "\n",
      "           DATASET\n",
      "TRAIN SIZE   177351\n",
      "VAL SIZE     21110\n",
      "TEST SIZE    15952\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = generate_stratified_train_val_test(data,val_ratio=0.1,test_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('val_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test_df')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
